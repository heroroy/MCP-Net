{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJAjv4qzuGC9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "# tensorflow\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow as tf\n",
        "tf.keras.layers.RandomFlip\n",
        "# image processing\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "# model / neural network\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VV3bGsF1mu-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2jCavItxV4W"
      },
      "outputs": [],
      "source": [
        "#mcp_Metacarpophalangeal joint\n",
        "path = \"/content/drive/MyDrive/MCP_arthritis\"\n",
        "  # List the files in the folder\n",
        "import cv2\n",
        "files = os.listdir(path)\n",
        "\n",
        "# Read the first three images\n",
        "RA_MCP=[]\n",
        "RA_MCP_label=[]\n",
        "for file in files:\n",
        "\n",
        "  # Construct the full path to the file\n",
        "\n",
        "  file_path = os.path.join(path, file)\n",
        "\n",
        "# Read the image\n",
        "\n",
        "  img = cv2.imread(file_path)\n",
        "  img= Image.fromarray(img,\"RGB\")\n",
        "\n",
        "  img= img.resize((224,224))\n",
        "  img= np.array(img)\n",
        "  RA_MCP.append(img)\n",
        "  RA_MCP_label.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqNf1h3Q0T_v"
      },
      "outputs": [],
      "source": [
        "base_dir = 'Arthritis'\n",
        "os.mkdir(base_dir)\n",
        "# create new folders inside base_dir\n",
        "RAmcp = os.path.join(base_dir, 'MCP')\n",
        "os.mkdir(RAmcp)\n",
        "Normalpatient = os.path.join(base_dir, 'Normal')\n",
        "os.mkdir(Normalpatient)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNWLJhv50fMn"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "# Get a list of images in each of the two folders\n",
        "folder_1 = os.listdir('/content/drive/MyDrive/MCP_arthritis')\n",
        "folder_2 = os.listdir('/content/drive/MyDrive/normal MCP')\n",
        "base_dir1='/content/Arthritis/MCP'\n",
        "base_dir2='/content/Arthritis/Normal'\n",
        "\n",
        "# Transfer the train images\n",
        "for image in folder_1:\n",
        "        # source path to image\n",
        "        src = os.path.join('/content/drive/MyDrive/MCP_arthritis', image)\n",
        "        # destination path to image\n",
        "        dst = os.path.join(base_dir1, image)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "for image in folder_2:\n",
        "        # source path to image\n",
        "        src = os.path.join('/content/drive/MyDrive/normal MCP', image)\n",
        "        # destination path to image\n",
        "        dst = os.path.join(base_dir2, image)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "th659tzQ2hm9"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "# Get a list of images in each of the two folders\n",
        "folder_1 = os.listdir('/content/drive/MyDrive/MCP_arthritis')\n",
        "folder_2 = os.listdir('/content/drive/MyDrive/normal MCP')\n",
        "base_dir1 = '/content/augmented_images' # Create a new destination folder\n",
        "base_dir2 = '/content/Mcpaugmented_images' # Create a new destination folder\n",
        "\n",
        "os.makedirs(base_dir1, exist_ok=True) # Create the destination folders if they don't exist\n",
        "os.makedirs(base_dir2, exist_ok=True)\n",
        "\n",
        "# Transfer the train images\n",
        "for image in folder_1:\n",
        "    # source path to image\n",
        "    src = os.path.join('/content/drive/MyDrive/MCP_arthritis', image)\n",
        "    # destination path to image\n",
        "    dst = os.path.join(base_dir1, image) # Copy to the new folder\n",
        "    # copy the image from the source to the destination\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "for image in folder_2:\n",
        "    # source path to image\n",
        "    src = os.path.join('/content/drive/MyDrive/normal MCP', image)\n",
        "    # destination path to image\n",
        "    dst = os.path.join(base_dir2, image) # Copy to the new folder\n",
        "    # copy the image from the source to the destination\n",
        "    shutil.copyfile(src, dst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHdPDSkyG3H_"
      },
      "outputs": [],
      "source": [
        "import imgaug.augmenters as iaa\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "\n",
        "# Create an output directory if it does not exist\n",
        "output_dir = '/content/Arthritis/MCP'\n",
        "#os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Define the augmentation sequence\n",
        "aug = iaa.Sequential([\n",
        "    iaa.Fliplr(0.5), # horizontal flips\n",
        "    iaa.Crop(percent=(0, 0.1)), # random crops\n",
        "    iaa.GaussianBlur(sigma=(0, 0.5)), # blur images with a sigma between 0 and 0.5\n",
        "    iaa.LinearContrast((0.75, 1.5)), # improve or worsen the contrast\n",
        "    iaa.AdditiveGaussianNoise(scale=(0, 0.05*255)), # add gaussian noise\n",
        "    iaa.Multiply((0.8, 1.2)), # make images darker or brighter\n",
        "    iaa.Affine(\n",
        "        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)}, # scale images\n",
        "        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)}, # translate images\n",
        "        rotate=(-25, 25), # rotate images\n",
        "        shear=(-8, 8) # shear images\n",
        "    )\n",
        "], random_order=True) # apply augmenters in random order\n",
        "\n",
        "# Load images\n",
        "image_paths = glob('/content/Arthritis/MCP/*.jpg')  # Change the pattern according to your images\n",
        "#images = [cv2.imread(img_path) for img_path in image_paths]\n",
        "images = []\n",
        "#img = cv2.imread(image_paths)\n",
        "#print(img)\n",
        "for img_path in image_paths:\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is not None:  # Check if image loaded successfully\n",
        "        images.append(img)\n",
        "    else:\n",
        "        print(f\"Failed to load image: {img_path}\")\n",
        "# Ensure we have the correct number of images\n",
        "num_generated_images = 0\n",
        "target_num_images = 500\n",
        "while num_generated_images < target_num_images:\n",
        "    for idx, img in enumerate(images):\n",
        "        if num_generated_images >= target_num_images:\n",
        "            break\n",
        "        augmented_image = aug(image=img)\n",
        "        output_path = os.path.join(output_dir, f'augmented_{num_generated_images:04d}.jpg')\n",
        "        cv2.imwrite(output_path, augmented_image)\n",
        "        num_generated_images += 1\n",
        "\n",
        "print(f\"Generated {num_generated_images} augmented images.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpknBJPcO-Uc"
      },
      "outputs": [],
      "source": [
        "import imgaug.augmenters as iaa\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "\n",
        "# Create an output directory if it does not exist\n",
        "output_dir = '/content/Arthritis/Normal'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Define the augmentation sequence\n",
        "aug = iaa.Sequential([\n",
        "    iaa.Fliplr(0.5), # horizontal flips\n",
        "    iaa.Crop(percent=(0, 0.1)), # random crops\n",
        "    iaa.GaussianBlur(sigma=(0, 0.5)), # blur images with a sigma between 0 and 0.5\n",
        "    iaa.LinearContrast((0.75, 1.5)), # improve or worsen the contrast\n",
        "    iaa.AdditiveGaussianNoise(scale=(0, 0.05*255)), # add gaussian noise\n",
        "    iaa.Multiply((0.8, 1.2)), # make images darker or brighter\n",
        "    iaa.Affine(\n",
        "        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)}, # scale images\n",
        "        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)}, # translate images\n",
        "        rotate=(-25, 25), # rotate images\n",
        "        shear=(-8, 8) # shear images\n",
        "    )\n",
        "], random_order=True) # apply augmenters in random order\n",
        "\n",
        "# Load images\n",
        "image_paths = glob('/content/Arthritis/Normal/*.jpg')  # Change the pattern according to your images\n",
        "#images = [cv2.imread(img_path) for img_path in image_paths]\n",
        "images = []\n",
        "#img = cv2.imread(image_paths)\n",
        "#print(img)\n",
        "for img_path in image_paths:\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is not None:  # Check if image loaded successfully\n",
        "        images.append(img)\n",
        "    else:\n",
        "        print(f\"Failed to load image: {img_path}\")\n",
        "# Ensure we have the correct number of images\n",
        "num_generated_images = 0\n",
        "target_num_images = 500\n",
        "while num_generated_images < target_num_images:\n",
        "    for idx, img in enumerate(images):\n",
        "        if num_generated_images >= target_num_images:\n",
        "            break\n",
        "        augmented_image = aug(image=img)\n",
        "        output_path = os.path.join(output_dir, f'augmented_{num_generated_images:04d}.jpg')\n",
        "        cv2.imwrite(output_path, augmented_image)\n",
        "        num_generated_images += 1\n",
        "\n",
        "print(f\"Generated {num_generated_images} augmented images.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zcV_4HwR08Q"
      },
      "outputs": [],
      "source": [
        "!zip -r '/content/drive/MyDrive/New_Arthritis.zip' '/content/Arthritis'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATiAgPC0LjFr"
      },
      "outputs": [],
      "source": [
        "base_dir = 'Arthritis'\n",
        "os.mkdir(base_dir)\n",
        "# create new folders inside base_dir\n",
        "mcp1 = os.path.join(base_dir, 'MCP')\n",
        "os.mkdir(mcp1)\n",
        "MCP2 = os.path.join(base_dir, 'NORMAL')\n",
        "os.mkdir(MCP2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3D9Z103HP2T"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Example paths (replace with your actual paths)\n",
        "source_folder = '/content/augmented_images'\n",
        "destination_folder = '/content/Arthritis/NORMAL/'\n",
        "\n",
        "# Create destination folder if it doesn't exist\n",
        "os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "# Function to transfer images\n",
        "def transfer_images(source_dir, dest_dir):\n",
        "    # Iterate over files in source_dir\n",
        "    for filename in os.listdir(source_dir):\n",
        "        source_file = os.path.join(source_dir, filename)\n",
        "        dest_file = os.path.join(dest_dir, filename)\n",
        "        # Transfer the file from source to destination\n",
        "        shutil.move(source_file, dest_file)\n",
        "\n",
        "# Transfer images from source_folder to destination_folder\n",
        "transfer_images(source_folder, destination_folder)\n",
        "\n",
        "print(\"Images transferred from\", source_folder, \"to\", destination_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CGhC2xnMvoe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Example paths (replace with your actual paths)\n",
        "source_folder = '/content/Mcpaugmented_images'\n",
        "destination_folder = '/content/Arthritis/MCP'\n",
        "\n",
        "# Create destination folder if it doesn't exist\n",
        "os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "# Function to transfer images\n",
        "def transfer_images(source_dir, dest_dir):\n",
        "    # Iterate over files in source_dir\n",
        "    for filename in os.listdir(source_dir):\n",
        "        source_file = os.path.join(source_dir, filename)\n",
        "        dest_file = os.path.join(dest_dir, filename)\n",
        "        # Transfer the file from source to destination\n",
        "        shutil.move(source_file, dest_file)\n",
        "\n",
        "# Transfer images from source_folder to destination_folder\n",
        "transfer_images(source_folder, destination_folder)\n",
        "\n",
        "print(\"Images transferred from\", source_folder, \"to\", destination_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQsucJNjPw8L",
        "outputId": "41aefd01-c6b2-4821-b1e1-2f2d527e5715"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install split-folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cf4Aglf0P0Lz"
      },
      "outputs": [],
      "source": [
        "import splitfolders\n",
        "splitfolders.ratio('/content/drive/MyDrive/Arthritis', output='new_arthritis', seed=1337, ratio=(0.75, 0.1, 0.15))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6PBCWqqXm50"
      },
      "outputs": [],
      "source": [
        "!zip -r '/content/drive/MyDrive/USG_arth.zip' '/content/new_arthritis'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSGaC7_sYB9f"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/drive/MyDrive/USG_arth.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Cvkj8KxQDJs"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('/content/new_arthritis/test/MCP',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('/content/new_arthritis/train/MCP',\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')\n",
        "valid_set = test_datagen.flow_from_directory('/content/new_arthritis/val/MCP',\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYDU32UsTlQN"
      },
      "outputs": [],
      "source": [
        "pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h019HL5STjUm",
        "outputId": "dbbc8bba-326b-4993-b9da-586ed1c4e0a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images found: 78\n",
            "Training set: 54 images\n",
            "Validation set: 12 images\n",
            "Test set: 12 images\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define directories\n",
        "original_data_dir = '/content/new_arthritis/test/MCP'\n",
        "train_dir = 'data/train'\n",
        "val_dir = 'data/val'\n",
        "test_dir = 'data/test'\n",
        "\n",
        "# Create directories if they do not exist\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# List all image files\n",
        "image_files = [f for f in os.listdir(original_data_dir) if os.path.isfile(os.path.join(original_data_dir, f))]\n",
        "#image_files = [\n",
        "    #f\n",
        "   # for f in os.listdir(original_data_dir)\n",
        "    #if os.path.isfile(os.path.join(original_data_dir, f))\n",
        "    #and f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')) # Filter for image files\n",
        "#]\n",
        "# Print the number of images found to help debug\n",
        "print(\"Number of images found:\", len(image_files))\n",
        "# Split the data\n",
        "train_files, test_files = train_test_split(image_files, test_size=0.3, random_state=42)\n",
        "val_files, test_files = train_test_split(test_files, test_size=0.5, random_state=42)  # Split remaining into val and test\n",
        "\n",
        "# Helper function to copy files to destination\n",
        "def copy_files(files, src_dir, dst_dir):\n",
        "    for file in files:\n",
        "        src_path = os.path.join(src_dir, file)\n",
        "        dst_path = os.path.join(dst_dir, file)\n",
        "        shutil.copy(src_path, dst_path)\n",
        "\n",
        "# Copy the files to their respective directories\n",
        "copy_files(train_files, original_data_dir, train_dir)\n",
        "copy_files(val_files, original_data_dir, val_dir)\n",
        "copy_files(test_files, original_data_dir, test_dir)\n",
        "\n",
        "print(f\"Training set: {len(train_files)} images\")\n",
        "print(f\"Validation set: {len(val_files)} images\")\n",
        "print(f\"Test set: {len(test_files)} images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hh-1D0x6T1qP",
        "outputId": "0eb493d6-a0ee-40d1-b079-8277064ef3b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: 53 images\n",
            "Validation set: 12 images\n",
            "Test set: 12 images\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define directories\n",
        "original_data_dir = '/content/new_arthritis/test/Normal'\n",
        "train_dir = 'data/train'\n",
        "val_dir = 'data/val'\n",
        "test_dir = 'data/test'\n",
        "\n",
        "# Create directories if they do not exist\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# List all image files\n",
        "image_files = [f for f in os.listdir(original_data_dir) if os.path.isfile(os.path.join(original_data_dir, f))]\n",
        "\n",
        "# Split the data\n",
        "train_files, test_files = train_test_split(image_files, test_size=0.3, random_state=42)\n",
        "val_files, test_files = train_test_split(test_files, test_size=0.5, random_state=42)  # Split remaining into val and test\n",
        "\n",
        "# Helper function to copy files to destination\n",
        "def copy_files(files, src_dir, dst_dir):\n",
        "    for file in files:\n",
        "        src_path = os.path.join(src_dir, file)\n",
        "        dst_path = os.path.join(dst_dir, file)\n",
        "        shutil.copy(src_path, dst_path)\n",
        "\n",
        "# Copy the files to their respective directories\n",
        "copy_files(train_files, original_data_dir, train_dir)\n",
        "copy_files(val_files, original_data_dir, val_dir)\n",
        "copy_files(test_files, original_data_dir, test_dir)\n",
        "\n",
        "print(f\"Training set: {len(train_files)} images\")\n",
        "print(f\"Validation set: {len(val_files)} images\")\n",
        "print(f\"Test set: {len(test_files)} images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCQRmP_UVAue"
      },
      "outputs": [],
      "source": [
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 973
        },
        "id": "C9GZCsvDVBpe",
        "outputId": "d9fa3afc-7023-4be1-8760-69ce9cc86366"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 762 images belonging to 2 classes.\n",
            "Found 100 images belonging to 2 classes.\n",
            "Found 154 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │     \u001b[38;5;34m23,587,712\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │          \u001b[38;5;34m2,049\u001b[0m │ resnet50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multiply_1 (\u001b[38;5;33mMultiply\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ resnet50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                           │                        │                │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ multiply_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m524,544\u001b[0m │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m257\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,049</span> │ resnet50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multiply_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ resnet50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                           │                        │                │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,114,562\u001b[0m (91.99 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,114,562</span> (91.99 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m526,850\u001b[0m (2.01 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">526,850</span> (2.01 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 441ms/step - accuracy: 0.9257 - loss: 0.1747 - val_accuracy: 1.0000 - val_loss: 0.0041\n",
            "Epoch 2/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
            "Epoch 3/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 7.8843e-04 - val_accuracy: 1.0000 - val_loss: 2.6508e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 3.8852e-04 - val_accuracy: 1.0000 - val_loss: 9.5544e-05\n",
            "Epoch 5/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 1.7947e-04 - val_accuracy: 1.0000 - val_loss: 6.6153e-05\n",
            "Epoch 6/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 1.0847e-04 - val_accuracy: 1.0000 - val_loss: 6.9610e-05\n",
            "Epoch 7/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - accuracy: 1.0000 - loss: 1.1478e-04 - val_accuracy: 1.0000 - val_loss: 6.2020e-05\n",
            "Epoch 8/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - accuracy: 1.0000 - loss: 7.9822e-05 - val_accuracy: 1.0000 - val_loss: 6.0167e-05\n",
            "Epoch 9/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 7.5524e-05 - val_accuracy: 1.0000 - val_loss: 5.9239e-05\n",
            "Epoch 10/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - accuracy: 1.0000 - loss: 6.6438e-05 - val_accuracy: 1.0000 - val_loss: 5.4380e-05\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 401ms/step - accuracy: 0.9870 - loss: 0.0116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.9935064911842346\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Conv2D, Multiply, Add\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "\n",
        "# Define the attention block\n",
        "def attention_block(inputs):\n",
        "    attention = Conv2D(1, kernel_size=1, activation='sigmoid')(inputs)\n",
        "    return Multiply()([inputs, attention])\n",
        "\n",
        "# Load the ResNet50 model\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = False  # Freeze the base model\n",
        "\n",
        "# Add attention block and new top layers\n",
        "inputs = Input(shape=(224, 224, 3))\n",
        "x = base_model(inputs, training=False)\n",
        "x = attention_block(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "outputs = Dense(1, activation='sigmoid')(x)  # Assuming binary classification\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define directories for training, validation, and test data\n",
        "train_dir = '/content/new_arthritis/train'\n",
        "val_dir = '/content/new_arthritis/val'\n",
        "test_dir = '/content/new_arthritis/test'\n",
        "\n",
        "# Create data generators\n",
        "train_datagen = ImageDataGenerator(rescale=0.2)\n",
        "val_datagen = ImageDataGenerator(rescale=0.2)\n",
        "test_datagen = ImageDataGenerator(rescale=0.2)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "model.summary()\n",
        "# Train the model\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=val_generator\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f\"Test accuracy: {test_acc}\")\n",
        "\n",
        "# Save the model\n",
        "model.save('resnet_with_attention.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "cnwKFhtG-cjQ",
        "outputId": "9ea6e032-72ee-4696-a4ad-6a6fcca620cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │     \u001b[38;5;34m23,587,712\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │          \u001b[38;5;34m2,049\u001b[0m │ resnet50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multiply (\u001b[38;5;33mMultiply\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ resnet50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                           │                        │                │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m524,544\u001b[0m │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m257\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,049</span> │ resnet50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ resnet50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                           │                        │                │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,168,264\u001b[0m (96.01 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,168,264</span> (96.01 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m526,850\u001b[0m (2.01 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">526,850</span> (2.01 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,053,702\u001b[0m (4.02 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,053,702</span> (4.02 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def get_gradcam_heatmap(model, img_array, layer_name):\n",
        "    # Get the model's output and gradients\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        loss = predictions[:, 0]  # Assuming binary classification and predicting class 1 (arthritis)\n",
        "\n",
        "    # Compute gradients of the loss with respect to the conv outputs\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "\n",
        "    # Mean of gradients for each feature map\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1))\n",
        "\n",
        "    # Multiply each channel in the feature map by the corresponding mean gradient\n",
        "    conv_outputs = conv_outputs[0]  # Remove the batch dimension\n",
        "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.reduce_mean(heatmap, axis=-1)  # Mean across channels\n",
        "\n",
        "    # Apply ReLU to the heatmap\n",
        "    heatmap = tf.maximum(heatmap, 0)\n",
        "    heatmap /= tf.reduce_max(heatmap)  # Normalize to [0, 1]\n",
        "\n",
        "    return heatmap.numpy()"
      ],
      "metadata": {
        "id": "5WocISi5-J7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image  # Import the 'image' module from keras\n",
        "\n",
        "img_path = '/content/drive/MyDrive/MCP_arthritis/48167-Afbeelding1.jpg'  # Update this path\n",
        "img = image.load_img(img_path, target_size=(224, 224))  # Resize according to your model's input size\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "img_array = img_array / 255.0  # Normalize if your model expects it"
      ],
      "metadata": {
        "id": "MvVmEI3-AWgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the layer name for which you want to generate the heatmap\n",
        "layer_name = 'conv2d_1'  # Change this to the last convolutional layer in your model\n",
        "\n",
        "# Get the Grad-CAM heatmap\n",
        "heatmap = get_gradcam_heatmap(model, img_array, layer_name)"
      ],
      "metadata": {
        "id": "aOk58oeI-OlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resize heatmap to the original image size\n",
        "heatmap = np.expand_dims(heatmap, axis=-1)\n",
        "heatmap_resized = tf.image.resize(heatmap, (img.size[1], img.size[0]))  # img.size returns (width, height)\n",
        "\n",
        "# Convert the heatmap to RGB\n",
        "heatmap_colored = plt.cm.jet(heatmap_resized.numpy()[:, :, 0])  # Use a color map for better visualization\n",
        "heatmap_colored = heatmap_colored[:, :, :3]  # Remove the alpha channel\n",
        "\n",
        "# Overlay the heatmap on the original image\n",
        "superimposed_img = heatmap_colored * 0.4 + img_array[0]  # Adjust alpha as necessary\n",
        "\n",
        "# Display the heatmap and the superimposed image\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(heatmap_resized[:, :, 0], cmap='jet')\n",
        "plt.title('Heatmap')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(superimposed_img)\n",
        "plt.title('Superimposed Image')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GII-s-Qv-RfI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}